# UniverDetect
Landmark detection on X-ray images is vital for disease screening, treatment, and prognosis. It serves as the foun-dation for downstream tasks such as segmentation, classification, and target detection. With the increasing number of X-ray examiners, the existing landmark detection methods show limitations. On the one hand, they serve specific data types, on the other hand, they can only learn a part of semantic information from this data set, thus affecting their popularization. To address these problems, we proposed a universal landmark detection model for mul-ti-domain X-ray images, named UniverDetect. By progressively acquiring local semantic information, global se-mantic insights, and anatomical structure knowledge at various levels, the model ensures that detected landmarks closely align with ground-truth labels. UniverDetect comprises three key components: the landmark detection module (LDM) utilizes a U-net network equipped with our innovative pyramid depthwise separable (PDS) convo-lution module for initial landmark detection. The landmark refinement module (LRM) integrates a fine-tuning module, comprising continuous extended convolution blocks. Finally, the landmark correction module (LCM) in-corporates a graph convolutional network (GCN) to rectify offset errors in partial landmark detection. An inherent feature of this model is its domain generalization capability, enabling continuous learning across diverse domains. This model has the capability to concurrently learn from 8 domains, covering 118 landmarks within a diverse da-taset of 5969 images. Extensive experiments conducted on multiple datasets demonstrate that our method consist-ently outperforms state-of-the-art approaches. This paper offers a versatile and effective solution to reduces the workload for doctors while providing precise quantitative analysis. 
